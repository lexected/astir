# "Hello Binary!"

As a first and simple example of astir's use let us try to write a grammar for a parser that recognizes the language consisting of all non-empty finite collections of whitespace-separated finite binary strings that do not start with whitespace themselves, denoted `L`. The following shall be our testing input for correct recognition

```
01011100 01001110  1010
010010101101    10111001
10
0011

```
and will be stored in `input.txt`.

## Writing the grammar
Thinking about the problem at hand, we need to write a grammar that describes exactly the language detailed above. It happens to be the case that the language to be described is in fact regular (proof: it is precisely the language generated by the regular expression `[01]+([ \t\n]+[01]+)*`), and hence we choose the most straightforward (and for the given task highly performant) parsing machine: the [finite automaton](https://en.wikipedia.org/wiki/Finite-state_machine). The input grammar file for astir is then just

```astir
finite automaton BinaryRecognizer {
    Language = ['0' '1']+ ([' ' '\t' '\n']+ ['0' '1']+)*;
}
```

We call the rule `language = ...;` a production. 

A keen eye might have noticed that all raw input elements (e.g. `0` or ` `) have been encapsulated in C-like strings and that the special characters (tabulator and line feed) were escaped in a C-like fashion (i.e. by `'\t'` and `'\n'` respectively). This is not a coincidence -- astir supports single-byte escape sequences with accordance to the ISO C11 standard. You can read more about capturing raw byte and raw text input with string literals in the language reference.

To generate the parser we simply invoke astir from the command line, i.e. by

```powershell
astir.exe BinaryRecognizer.astir
```

on Windows, or by

```bash
./astir grammar.astir
```

on Linux. You can also specify where your output files should go using the `--outputDirectory` option, but they will appear in the current directory by default.

## Using the generated parser
You will notice two output files appearing in your output directory, `BinaryRecognizer.h` and `BinaryRecognier.cpp`. If you open `BinaryRecognier.h` you will find a piece of code similar to

```cpp
class BinaryRecognizer {
public:
    BinaryRecognizer();

    std::shared_ptr<OutputProduction> apply(InputStream& rs);
    std::list<std::shared_ptr<OutputProduction>> process(InputStream& rs);

    bool lastApplicationSuccessful() const ;
    void reset();
    ...
}
```

which gives you everything you need to know about the interface of the machine you want to work with. At this point, to run our example, all you need to do is to write a `main` function that tries to apply the recognizer, and reports on the success of its attempt.

```cpp
#include <fstream>
#include "BinaryRecognizer.h"

int main() {
	std::ifstream f("input.txt");

	TextFileStream tfs("input.txt", f);

	BinaryRecognizer::BinaryRecognizer tokenizer;
	tokenizer.apply(tfs);

	if(tokenizer.lastApplicationSuccessful()) {
		std::cout << "The input in 'input.txt' was recognized; it indeed belongs to our language" << std::endl;
		return 0;
	} else {
		std::cout << "The input in 'input.txt' was not recognized; it does not belong to our language" << std::endl;
		return 1;
	}
}
```

Compile, run, and enjoy.

## Refactoring
Observe that the regex `[01]` appears in the recognizer's grammar a couple of times. If we were to think about making our parser an octal recognizer instead, we would have to replace every occurence of `[01]` with `[01234567]`. Doing so could prove laborous, and what's worse, if we were to forget about some occurence of `[01]`, the resulting parser would be at the risk of not functioning properly. We shall thus declare a separate named regular expressions for the binary digit, and then refer to this regex by its name from the `language` production. We can do the same with the whitespace as well just to make our intentions clearer.

```astir
finite automaton BinaryRecognizer {
    regex binaryDigit = ['0' '1'];
    regex whiteSpaceCharacter = [' ' '\t' '\n'];
    Language = binaryDigit+ (whiteSpaceCharacter+ binaryDigit+)*;
}
```

Finally, once we have both productions and pure regular expressions present in our machine, it might just be better to explicitly state that the `language` production is indeed a `production` to steer absolutely clear of ambiguity. The contents of the final grammar file (`BinaryRecognizerRefactored.astir`) are then

```astir
finite automaton BinaryRecognizer {
    regex binaryDigit = ['0' '1'];
    regex whiteSpaceCharacter = [' ' '\t' '\n'];

    production Language = binaryDigit+ (whiteSpaceCharacter+ binaryDigit+)*;
}
```

## Capturing typed productions
We possess a parser that can tell us whether the given input belongs to `L` or not, but it is not as useful as it could easily be. When a human looks at the contents of `input.txt`, they recognize individual binary strings like `01011100` or `10`, and even possibly associate them with some meaning. The process of uniting strings of characters into larger but still simple structures is often referred to called [lexical analysis](https://en.wikipedia.org/wiki/Lexical_analysis) or *tokenization*. Let us therefore reformulate the task of our parser from "testing whether input belongs to `L` or not" to "recognizing and capturing individual entities of the language `L`". These entities shall in particular be binary strings and whitespace separators.

We will make two separate productions, `BinaryString` and `WhiteSpace`.

```astir
finite automaton BinaryTokenizer {
    regex binaryDigit = ['0' '1'];
    regex whiteSpaceCharacter = [' ' '\t' '\n'];

    production BinaryString = binaryDigit+;
    production WhiteSpace = whiteSpaceCharacter+;
}
```

> Notice that the language recognized by the above grammar is actually strictly larger than `L`. While `L` explicitly disallowed input to begin with whitespace (i.e. `\n010` would not have been recognized), the above-specified tokenizer would happily recognize (tokenize) such strings.

If we were to run `astir` and generate the output files now, we would find that the `apply` function would return only a single `BinaryString` or `WhiteSpace` at a time. We could then loop conditionally on `lastApplicationSuccessful()`, but there is a convenience method `process` available in the `BinaryRecognizer` class as well!

```cpp
#include <fstream>
#include "BinaryTokenizer.h"

int main() {
	std::ifstream f("input.txt");

	TextFileStream tfs("input.txt", f);

	BinaryTokenizer::BinaryTokenizer tokenizer;
	auto listOfTokens = tokenizer.process(tfs);

	for(const auto& tokenPtr : listOfTokens) {
        if(tokenPtr->type == BinaryTokenizerTerminalType::BinaryString) {
            std::cout << "[" << tokenPtr->locationString() << "] BinaryString: " << tokenPtr->raw << std::endl;
        } else {
			std::cout << "[" << tokenPtr->locationString() << "] WhiteSpace of length " << tokenPtr->raw.length() << std::endl;
		}
    }

	return 0;
}
```

There is the possibility of using one root `Language` production instead, simply by altering the grammar appropriately, disabling the default "rootness" of productions, and using the `root` keyword.

```astir
finite automaton BinaryTokenizer with productions_nonroot_by_default {
    regex binaryDigit = ['0' '1'];
    regex whiteSpaceCharacter = [' ' '\t' '\n'];

    production BinaryString = binaryDigit+;
    production WhiteSpace = whiteSpaceCharacter+;

    root production Language = BinaryString (WhiteSpace BinaryString)*;
}
```

> This grammar once again describes `L` and not a strict superset of `L`.

If you `astir` this grammar though, you will find out that some information is lost. The whitespace we do not really care about much, but the binary strings themselves could be kind of useful. There is a way `astir` deals with this that is completely independent of the target language: *regex actions*. Without going into much detail on this here (after all, this should only be a "Hello ~~World~~ Binary!" example), here is a solution that ignores whitespace but keeps a record of the binary strings encountered.

```astir
finite automaton BinaryTokenizer with productions_nonroot_by_default {
    regex binaryDigit = ['0' '1'];
    regex whiteSpaceCharacter = [' ' '\t' '\n'];

    production BinaryString = binaryDigit+;
    production WhiteSpace = whiteSpaceCharacter+;

    root production Language {
        BinaryString list strings;
    } = BinaryString@push:strings (WhiteSpace BinaryString@push:strings)*;
}
```

## Ignoring whitespace
When tokenizing, it is often desirable to record some productions recognized in the input stream, and discard others.

When working with finite automata, every production is considered to be a `root` production by default unless the automaton has been configured otherwise (possibly by the use of `productions_nonroot_by_default` machine attribute as in some of the previous examples). The `root` productions are the ones recognized on the top level of tokenization and returned by the `apply` method. A non-root production will not be recognized on its own, but could be recognized as a part of some other production if referred to, as we have already seen. There is, however, a third possible rootness setting for productions (and in fact, for categories as well, but more on that later): `ingored root`.

The setting is really self-explanatory. Here is an example use

```astir
finite automaton BinaryTokenizer {
    regex binaryDigit = ['0' '1'];
    regex whiteSpaceCharacter = [' ' '\t' '\n'];

    production BinaryString = binaryDigit+;
    ignored root production WhiteSpace = whiteSpaceCharacter+;
}
```

Some would argue that by explicitly specifying some productions as `root` or `ignored root` one should proceed to do the same with all type-forming statements in the machine as a matter of good coding practice. One would guess they are also the same people who write `signed` and `unsigned` before every integer declaration in C-likes.