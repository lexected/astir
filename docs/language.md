# Language

The astir grammar-specification language could be considered a version of EBNF extended by regular expressions and signficantly supplemented by semantic declarations and action mechanisms.

Internally, astir input is first analysed lexically into several types token. Then, skeleton syntax definitions are parsed by a syntactic analyzer, and finally, a few universal semantic checks are performed before the AST is passed onto the output code generation mechanisms. We shall only concern ourselves with the first three of the aforementioned parts.

If you are not a keen reader, you can skip directly to the astir grammar written in ... the astir grammar, [here](#the_entire_grammar).

## Lexical structure

### The input character set

Astir's internal lexer takes ASCII text input.

### Registered tokens

The lexer recognizes all of the following types of tokens. Once recognized, the tokens are consumed on the input stream and are either registered or ignored (skipped).

The tokens listed below are ignored
* space characters: whitespace (`' '`), tabulator (`'\t'`), carriage return (`'\r'`), line feed (`'\n'`), and the zero character (`'\0'`)
* C-style line comments, spanning from the occurence of `//` until the end of the line (market by the line feed character)
* C-style multi-line comments, spanning from the occurence `/*` until the first consecutive occurence of `*/` (i.e. comment nesting is not supported)

The tokens below are registered
* keywords (see [the list of keywords](#list_of_keywords))
* identifiers, that is all the strings of the langauge generated by the regular expression `[a-zA-Z_][a-zA-Z0-9_]*`
* numbers (non-negative integers), that is the strings of the language generated by `[0-9]+`
* strings (non-negative integers), that is arbitrary strings that may include escape sequences according to the C11 standard (limited to singe-byte characters)
    * examples of escape sequences: `\n`, `\v`, `\t`, `\xAB`
* parentheses (`(`, `)`), square brackets (`[`, `]`), and curly brackets (`{`, `}`)
* the following operators
    * semantic: `=`, `:`, `;`, `<-`, `,`, `&`
    * regex: `.`, `^`, `$`, `?`, `*`, `+`, `/`, `-`
    * actions: `@`

### List of keywords

The following tokens, which would otherwise be recognized as identifiers, are reserved as keywords

* for a general machine declaration
    * `uses`
    * `on`
    * `with`
* for machine type specification
    * `finite`
    * `automaton`
    *  `LL`
    * `parser`
* for machine attributes
    * `productions_terminal_by_default`
    * `productions_nonterminal_by_default`
    * `productions_root_by_default`
    * `productions_nonroot_by_default`
    * `categories_root_by_default`
    * `categories_nonroot_by_default`
    * `ambiguity_disallowed`
    * `ambiguity_resolved_by_precedence`
* for machine statement declaration
    * `ignored`
    * `root`
    * `terminal`
    * `nonterminal`
    * `category`
    * `production`
    * `pattern`
    * `regex`
* for field listing
    * `flag`
    * `raw`
    * `item`
    * `list`
* for actions
    * `flag`
    * `unflag`
    * `capture`
    * `empty`
    * `append`
    * `prepend`
    * `set`
    * `unset`
    * `push`
    * `pop`
    * `clear`
* special reuse
    * `empty` to designate empty regex (an alternative to `()` or `""`)
    * `finite` when in the machine type specification `LL(finite) parser`

## Syntactic structure

The syntactic analyzer (parser) of the astir core recognizes creates a `SyntaxTree` internal entity for every file it is asked to processes. This `SyntaxTree` entity holds a list of machines of various types, which in turn hold a list of statements. Each statement (if attributable) may then hold a list of categories it inherits, list fields, and if it is a rule statement it will also hold a regex.

### Machine definitions
Machine definitions consist of six parts. The first five - the machine type specification, name, and the `with`, `on`, and `uses` clauses - form the machine's declaration, whereas the last part - the machine body specified between the curly brackets following the declaration - completes the definition. 

The following is the grammar for Astir's machine definitions.

```astir
production machineDefinition =
	machineType IDENTIFIER
        (KW_WITH machineOptionList)?
        (KW_ON IDENTIFIER)?
        (KW_USES identifierList)? CURLY_LEFT
            machineDefinitionBody
        CURLY_RIGHT
	;
```

#### Machine type
The machine types supported by the grammar directly mirror the machine types supported internally by Astir. There are currently only two main types of machines allowed: the `finite automaton` and the `LL(k/finite) parser`.

```astir
pattern machineType =
	KW_FINITE KW_AUTOMATON
	| KW_LL PAR_LEFT (NUMBER|KW_FINITE) PAR_RIGHT KW_PARSER
	;
```

#### The `with` clause
The `with` clause of the machine definition allows the parser designer to overwrite the default semantics of the machine or to give further instructions to the Astir's generator on how some possible generation incidents should be handled. More on the use of machine attributes can be found under [Machine attributes](#machine_attributes) and in the [Generation](/generation.md) reference. 

```astir
pattern machineOptionList =
	machineOption (OP_COMMA machineOption)*
	;

pattern machineOption = 
	KW_PRODUCTIONS_TERMINAL_BY_DEFAULT
	| KW_PRODUCTIONS_NONTERMINAL_BY_DEFAULT
	| KW_PRODUCTIONS_ROOT_BY_DEFAULT
	| KW_PRODUCTIONS_NONROOT_BY_DEFAULT
	| KW_CATEGORIES_ROOT_BY_DEFAULT
	| KW_CATEGORIES_NONROOT_BY_DEFAULT
	| KW_AMBIGUITY_DISALLOWED
	| KW_AMBIGUITY_RESOLVED_BY_PRECEDENCE
	;
```
#### The `on` clause
The `on` clause serves to allow the user to specify the [input machine](#input_machines). If no `on` clause is specified in the definition, it is assumed that the machine takes raw input. There is no way to specify the intention to accept raw input explicitly (e.g. `finite automaton MyAutomaton on raw {};`) will not compile.

#### The `uses` clause
The `uses` clause is for specifying [dependency machines](#dependency_machines). While on the syntactic level all machines can have the `uses` clause, on the semantic level not all machines are permitted to have dependency machines.

```
pattern identifierList =
    IDENTIFIER (OP_COMMA IDENTIFIER)*
    ;
```

#### Machine definition body
Is simply a list of machine statements.

```
pattern machineDefinitionBody =
    statement*
    ;
```

### Machine component definitions (machine statements)

On the outset, the machine statements can be attributed or non-attributed, type-forming or non-type-forming, and rule statements or categories.

By a *declaration* we shall mean the part of the statement that introduces is type, specifies its name, and provides elaborations for its particular type (e.g. the elaboration for attributable statements, the rootness elaboration for type-forming statements, and terminality elaboration for productions, all defined below).

By a *definition* we shall mean the entire statement, and in the case of rule statements (again, defined below) we shall also talk about the definition body.

For example, in `category CAT`, the entire statement is both a declaration and a definition. In `terminal production TIGER : CAT  = 'meow'+`, `terminal production TIGER : CAT` is the declaration part of the definition, the entire statement is the definition of a `TIGER`, and the repetitive regular expression `'meow'+` is the definition body of the production. 

#### Attributable and non-attributable statements

Categories, `production`s, , and `pattern`s are attributable statements, `regex`es are non-attributable.

Attributable statements can be attributed via the attributable statement elaboration. On the syntactic level, the elaboration is just listing the categories that are to be inherited by the given attributed statement and listing of the statement's fields. See the syntax below

```astir
pattern attributableStatementElaboration =
	(OP_COLON declarationNameList)? CURLY_LEFT memberDeclaration* CURLY_RIGHT
	;

production memberDeclaration =
	KW_FLAG IDENTIFIER OP_SEMICOLON
	| KW_RAW IDENTIFIER OP_SEMICOLON
	| IDENTIFIER (KW_LIST|KW_ITEM)? IDENTIFIER OP_SEMICOLON
	;
```

Thus, the following give examples of valid elaborations

```astir
production Long : OneCategory, AnotherCategory, YetAnotherCategory = empty;

production Small { };

category IndependentCategory {
    Small item thatWasOverlooked;
};

category JointCategory : MyCategory, YourCategory, IndependentCategory {
    flag GermanFlag;
    flag FrenchFlag;
    raw fish;
    Long list ofBritishDemands;
};
```

#### Type-forming and non-type-forming statements

Categories and `production`s are type-forming statements. On the syntactic level that means that they can be explicitly specified as `root` or `ignored root` statements, via the type-forming statement elaboration.

```astir
pattern typeFormingStatementElaboration =
	(KW_ROOT|KW_IGNORED KW_ROOT)?
	;
```

#### Rule statements
Productions, `pattern`s, and `regex`es are rule statements, since they can (and have to be) given a specific regular expression in order for their definition to be complete. The regular expression is associated with the declaration part of rule statement definition by the equals (`=`) operator. The rule statement body is what follows the equals operator, and it is parsed according to the following grammar

```astir
production ruleStatementBody = 
	disjunctiveRegex?
	;
```

#### Categories
Categories are declared using the `category` keyword. They are attributable, type-forming statements. The following is the syntax for their declaration

```astir
production categoryStatement =
	typeFormingStatementElaboration KW_CATEGORY IDENTIFIER attributableStatementElaboration OP_SEMICOLON
	;
```

Note that categories may not be specified as `terminal` or `nonterminal`. More on that can be found in the [Terminality](#terminality) subsection.

#### Productions
Productions are the default type of statement. They can be explicitly declared using the `production` keyword, but it is not necessary. They are attributable, type-forming, rule statements, but moreover, they can be explicitly specified as either `terminal` or `nonterminal`.

Syntax
```astir
production productionStatement =
	typeFormingStatementElaboration
    terminalityElaboration
    KW_PRODUCTION? IDENTIFIER attributableStatementElaboration OP_EQUALS
        ruleStatementBody
    OP_SEMICOLON
	;

pattern terminalityElaboration =
	(KW_TERMINAL | KW_NONTERMINAL)?
	;
```

Default (i.e. when not explicitly specified) terminality and rootness depends on the type of the machine the statement is defined in and the machine attributes applied. Assuming we are defining the statements inside a `finite automaton`, all of the following options are fully equivalent

```astir
Example = empty;
production Example = empty;
terminal Example = empty;
terminal production Example = empty;
root Example = empty;
root terminal Example = empty;
root terminal production Example = empty;
```

#### Patterns

Patterns are attributable, non-type-forming, rule statements, and are declared with the `pattern` keyword. On the syntactic level they differ from productions in that they can not have their rootness specified (they are never roots of any machine) and can not be declared as `terminal` or `nonterminal`. Their syntax is thus similar but simpler

```astir
production patternStatement =
	KW_PATTERN IDENTIFIER attributableStatementElaboration OP_EQUALS
        ruleStatementBody
    OP_SEMICOLON
	;
```

An example

```astir
pattern ForLife = (WAKE_UP WORK HAVE_FUN SLEEP)+;
```

#### Regexes

Regexes (short for regulr expressions) are non-attributable, non-type-forming rule statements declared with the help of the `regex` keyword. The grammar for their definition is thus probably the simplest of them all

```astir
production regexStatement =
	KW_REGEX IDENTIFIER OP_EQUALS
		ruleStatementBody
	OP_SEMICOLON
	;
```

### Regular expressions and action tags

The following is the syntax for regular expressions recognized by the astir parser.

```astir
production disjunctiveRegex =
	conjuctiveRegex (OP_OR conjuctiveRegex)*
	;

production conjunctiveRegex =
	rootRegex+
	;

production rootRegex =
	(repetitiveRegex | atomicRegex) actionTag*
	;

production actionTag = 
	OP_AT action OP_COLON IDENTIFIER
	;

pattern action =
	| KW_FLAG
	| KW_UNFLAG
	| KW_CAPTURE
	| KW_EMPTY
	| KW_APPEND
	| KW_PREPEND
	| KW_SET
	| KW_UNSET
	| KW_PUSH
	| KW_POP
	| KW_CLEAR
	;

production repetitiveRegex =
	atomicRegex OP_QM
	| atomicRegex OP_STAR
	| atomicRegex OP_PLUS
	| atomicRegex CURLY_LEFT NUMBER, NUMBER CURLY_RIGHT
	;
	
production atomicRegex =
	PAR_LEFT disjunctiveRegex PAR_RIGHT
	| SQUARE_LEFT OP_CARET (STRING|regexRange)+ SQUARE_RIGHT
	| SQUARE_LEFT (STRING|regexRange)+ SQUARE_RIGHT
	| STRING
	| (KW_EMPTY | PAR_LEFT PAR_RIGHT)
	| OP_DOT
	| referenceRegex
	;

production regexRange =
	STRING OP_DASH STRING
	;

production referenceRegex =
	IDENTIFIER
	;
```

Observe the action tags - there can be multiple action tags associated with every "root regex", and they follow a very simple syntax. Notice also that currently there is no bracket notation for a list of equivalent (in terms of their unit length) terminal or nonterminal alternatives - one can specify the regular expression `['a' 'b' 'c' 'd']` but can not do `[TERMINAL_FIRST TERMINAL_SECOND TERMINAL_THIRD]`; instead, `(TERMINAL_FIRST | TERMINAL_SECOND | TERMINAL_THIRD)` must be used.

## Semantic structure

The semantic structure of a astir grammar specification, at least on the surface, corresponds completely to the syntactic structure of the given specification. Every machine is declared and defined by a single machine definition, and every statement is given by a single statement definition. Internally, specific machines, like the finite automaton or the LL(finite) parser will build more complex structures that will aid them during the phase when the output code is generated. We shall not concern ourselves with this internal representation here and only touch on the universal semantic characteristics that span all machine types.

### Machines

#### Roots
Roots are the starting points for the machine recognition/parsing process of its input. Conventionally, parser tend to have just one root (although more can be specified in `astir`) while finite automata tend to have multiple.

Every type-forming statement may have rootness of one of the following three types: *root*, *ignored root*, and *unspecified*.

* Unspecified is the default rootness when neither `root` or `ignored root` elaborations have been used in the declaration of the statement. It may be overridden by the `productions_root_by_default` or `categories_root_by_default` machine attributes in the `with` clause of machine declaration (or by their default setting, see [Machine attributes](#machine_attributes) for more detail), but unless that happens the unspecified rootness is interpreted as the statement not being a root statement. If the statement isn't referenced in any other root statement (directly or indirectly by chain reference), it won't affect the parsing ability of the machine in any way.
* Root rootness instructs the appropriate machine generator that the statement is to be considered among the candidates for the root parse. Broadly speaking, specifying multiple roots in say LL(k) parser is equivalent to specifying just one root category that is inherited by all the "formerly root" statements. The singificant difference is that when multiple terminal roots are specified, uniting them under one terminal root will lead to loss of their type information (they will all be lumped together under one root terminal), while uniting them under one non-terminal root will rob any machine that might use the outputs of the machine being defined of the performance bonus associated with having *purely terminal input* (see [Input machines](#input_machines)).
* Ignored root rootness instructs the machine generator that while any match produced by the use of the statement shall be consumed from the input, it shall not be stored and passed on as output. Typical uses include the removal of whitespace or comments during tokenization.

    ```astir
    finite automaton Tokenizer {
        root IDENTIFIER = ['a'-'z' 'A'-'Z' '_']+;
        ignored root WHITESPACE = [' ' '\t' '\n']+;
        ...
    }
    ```

#### The specification scope
All machines within one sepcification document (file) can freely refer to any other machine in that document regardless of the order in which they were defined, with the only restriction being that there may be no circular references that would lead to an infinitely-recursive lookup. For example, a `SecondaryAutomaton` may well be defined before the `PrimaryAutomaton` and still use the output of the `PrimaryAutomaton` for its input (via the `on` clause), but under no circumstances may it be the case that the `PrimaryAutomaton` will then list the `SecondaryAutomaton` as its own input, or use the `SecondaryAutomaton` as its dependency. While this would be a simple 2-cycle (one can almost hear a graph theorist scratching his head -- ha, gotcha, we are using multigraphs!), it is not hard to come up with an example in which there are three or more machines involved.

When multiple machines are defined in one document, we say that they share the **specification scope**.

#### Input machines

Every machine may list at most one **input machine** in the `on` clause. Input machine, if specified, is the machine whose *output* will be fed into to current machine for processing. If no input machine has been specified, it is assumed that the machine being defined accepts *raw input* (roughly meaning raw byte or text input). There are restrictions on which machines can accept what types of input, mainly due to their construction principles.

We say that a machine has *purely terminal output* or *purely terminal roots* if all roots of that machine are terminal. Let `A` and `B` be machines. We say that `B` has *purely terminal input* if *B* takes the output of *A* as its input and *A* has purely terminal output.

Categories are generally considered non-terminal, so the property of having purely terminal output can be broken by introducing a single root category. Finite automata, for example, require that their input is purely terminal as they are table driven for performance. The LL(finite) parsers on the other hand have no such requirement, although they may have slightly higher performance if their input is purely terminal (conditional on the output language chosen and the optimisation of the runtime implementation). 

#### Dependency machines

Some machines may list one or more **dependency machines** in the `uses` clause. Every dependency machine listed must accept input identical to the input accepted by the machine being defined - that is, if machine `ComplicatedParser` is `on Tokenzier`, all dependency machines of `ComplicatedParser` must also be `on Tokenizer`, and similarly if `ComplicatedParser` was to accept only raw input. Finite automata, for example, do not allow the use of dependency machines, mainly because of the simplicity of their operation (a straightforward table lookup with some bits of backtracking and action information), but LL(k) parsers do. In fact, the parsing behaviour (though not the performance) of a LL(k) parser `on SomeFiniteAutomaton` and with `uses SomeFiniteAutomaton` would be identical. 

There are two main use cases for dependency machines.

* improved performance of lookahead. A finite automaton can be used to do selective lookahead in order to identify whether to proceed with parsing of a specific alternative.
* mixing of parsing strategies and algorithms. While LL(k) have generally good performance and are easy to debug and read, they struggle with left-recursive grammars and with the implementation of concepts like operator precendence. In such cases the LL(k) parser can be used as the main parser parsing the declarative parts of language, while and LR(0) or LALR parser can be invoked to handle expression parsing. This machine *nesting* use also allows to extend the spectrum of grammars one parser can recognize.

We say that `A`, `B` are *chained* or in a chain succession if `B` is `on` `A`. This extends to multiple machines in the obvious way.

We say that `A` and `B` are *nested*, or more specifically, that `A` is *nested (into)* `B` if `B` uses `A` and refers to some of its roots.

#### Machine attributes
Machine attributes are a tool that gives the parser designed more power over the behaviour of some parts of the machine. The following are the machine attributes that can currently be recognized

* `ProductionsTerminalByDefault`
* `ProductionsRootByDefault`
* `CategoriesRootByDefault`
* `AmbiguityResolvedByPrecedence`

Every machine attribute is always either `true` or `false`, and the default state depends on the machine type. Further, the every machine attribute can be *set* or *not set*. Machine attribute for a given machine is set by explicitly listing an attribute keyword in the `with` clause of the machine's declaration. Setting machine attribute changes the state to `true` or `false` (depending on whether the *positive* or *negative* attribute keyword has been used), and once attribute has been set, it can not be set or unset again within the same `with` clause. Trying to do so will result in an error.

Here is the list of the supported machine attributes again with the positive and negative keywords, in this order.

* `ProductionsTerminalByDefault`: `productions_terminal_by_default`, `productions_nonterminal_by_default`
* `ProductionsRootByDefault`: `productions_root_by_default`, `productions_nonroot_by_default`
* `CategoriesRootByDefault`: `categories_root_by_default`, `categories_nonroot_by_default`
* `AmbiguityResolvedByPrecedence`: `ambiguity_resolved_by_precedence`, `ambiguity_disallowed`

For example, LL(finite) start with `AmbiguityResolvedByPrecedence` `false` but unset. Specifying `with ambiguity_resolved_by_precedence` will set `AmbiguityResolvedByPrecedence` to `true` while `with ambiguity_disallowed` will set `AmbiguityResolvedByPrecedence` to `false`. In both cases the attribute will then be set, and hence trying to change the setting, for example as in `with ambiguity_resolved_by_precedence, categories_root_by_default, ambiguity_disallowed` will lead to an error.

You can find more about the defaults of individual machines in [Generation](#generation).

### Statements

Statements are the basic building blocks of machines. While in some generated outputs (like for LL(finite) parsers) you may be able to identify the individual statements that the parts of the parsing mechanism were generated from, it is in general not the case, and if you have specific questions about behaviour of various parsing rules under this or that machine type you should check out [Generation](#generation).

#### Terminality

Astir's `production`s can be terminal or non-terminal. One could be tempted to say that this distinction exists for historic reasons on the engineering side (terminal types carry around more type information and can thus be identified faster), but on the theory side, especially when it comes to parsing theory, the meaning is different and still holds. Indeed, under the terminology of LL grammars even astir's patterns or disjunctive regular expressions could be considered non-terminals.

Astir's `terminal production`s differ from `nonterminal production`s by having

* an internal type field that can be easily checked during parsing (giving a performance boost to machines that accept only terminals on input)
* an internal raw field in which the underlying, original raw input that has been parsed into the given token, is stored

When a terminal is produced by a secondary machine, raws of the underlying terminals are concatenated to produce the raw for the higher-order terminal.

Terminality is more of a flexible concept than it initially appears to be. Some machines can see through non-terminality of categories in the following way: if a category is inherited only by terminal productions, instead of dynamically evaluating the type of the category, the generator for the currently generated machine may opt for trying whether the token on the input is one of those inherited by the category instead. This sort of optimisation is, however, rare.

#### The statement scope
We say that `M` *lists* statement `S` if `S` is defined in the body of `M`.

We say that `S` *is available in* `M` if `M` lists `S`, or `I` is the input machine of `M` and `S` is available in `I`, or `D` is a machine dependency of `M` and `S` is available in `D`.

We then define the *statement scope* of a machine `M` to be the set of all statements `S` such that `S` is available in `M`.

#### Statement referencing
A specific type of a regex, a *reference regex*, can be found in the [grammar](#the_entire_grammar). This regex is really only an encapsulation of the application of the rule of a statement. It is, however, necessary, that the statement referred to is in the statement scope of the current machine.

How a reference regex is interpreted by the generator then depends on multiple things. References to patterns generally lead to a copy-paste the logic of the pattern, and that is also why LL(finite) parsers or finite automata disallow patterns referencing themselves recursively through purely-pattern paths.

References to root productions of the input machine are usually generated as a simple comparison check or table lookup, whereas the references to root productions of dependency machines may call in some heavy tokenisation and stream in-peeking weaponry.

### Fields and actions

Fields of attributable statements correspond to the notion of fields or member variables in object-oriented languages. They are introduced in the attributable-statement elaboration and are inherited from categories. 

Plenty of examples have been presented in the *Fields* section of the [Something regular](/#something_regular) guide.

#### The field scope
We say that an attributable statement `S` *lists* a field if it is declared in the body of the attributable-statement elaboration of `S`.

We say that a field `F` *is available on* an attributable statement `S` if `S` lists `F` or there exists a category `C` such that `F` inherits `C` and `S` is available in `C`.

We then define the *field scope* of an attributable statement `S` to be set set of all fields `F` such that `F` is available on `S`.

#### Storage types and corresponding actions
Astir's fields have two built-in types, `flag` and `raw`, and two kinds of _plurality_, `item` and `list`, for all custom types. A custom type is introduced to the context (more specifically the statement scope) by a relevant type-forming statement.

We say that a type `T` is a template type if `T` is one of `flag`, `raw`, `<> item`, and `<> list`. There are always exactly four template types available.

We say that a type `T` is a pluralised type if `T` is `flag`, or `T` is `raw`, or if `U` is a custom type and `T` is either `U list` or `U list`. So, if there are 10 type-forming statements in the current statement scope, then there are `22` pluralised types available for our use.

We can partition all astir's actions in such a way that there will be a one-to-one correspondence between the parts of the partition and the set of template types. In other words, the actions, and only the actions that we will list under a template type can be used with that particular template type.

##### Flag fields
Flag fields can be either `flag`ged or `unflag`ged. You can always assume that the flag field is in the "unflagged" state until flagged. In C++ this corresponds to a `bool` field being `false` until it has been set to `true` by the `flag` action.

##### Raw fields
Raw fields roughly correspond to strings in most languages. One can `capture`, `append`, or `prepend` parts of input to a raw field, and for completeness, raw fields can also be emptied by the `empty` action.

##### Item fields
Item fields do not have a type on their own -- they need a name of a type-forming statement for their storage specification to be complete. When declaring an item field the keyword `item` is optional.

##### List fields
The type-forming statement referenced does not have to be a statement within the current machine. Indeed, all types created by type-forming statements of the input machine (the one following the `on` keyword in the machine declaration) or machine dependencies (the machines listed after the `uses` keyword), their dependencies, etc..

Item fields can be `set` and `unset`, but only by references to the type-forming statement of their type or, in case of categories, by references to type-forming statements that inherit that category (directly or indirectly). Similar to the behaviour of `flag` fields, every item field is considered to be in the "`unset`" state until set.

## The entire grammar
This grammar file can also be found under the `astir/Resources` folder of the code repository.

```astir
production specification = 
	specificationStatement*
	;

production specificationStatement =
	machineDefinition
	| usesStatement
	;

production usesStatement =
	KW_USES STRING
	;

production machineDefinition =
	machineType IDENTIFIER
        (KW_WITH machineOptionList)?
        (KW_ON IDENTIFIER)?
        (KW_USES IDENTIFIER (OP_COMMA IDENTIFIER)*)? CURLY_LEFT
            machineDefinitionBody
        CURLY_RIGHT
	;

pattern machineType =
	KW_FINITE KW_AUTOMATON
	| KW_LL PAR_LEFT (NUMBER|KW_FINITE) PAR_RIGHT KW_PARSER
	;

pattern machineOptionList =
	machineOption (OP_COMMA machineOption)*
	;

pattern machineOption = 
	KW_PRODUCTIONS_TERMINAL_BY_DEFAULT
	| KW_PRODUCTIONS_NONTERMINAL_BY_DEFAULT
	| KW_PRODUCTIONS_ROOT_BY_DEFAULT
	| KW_PRODUCTIONS_NONROOT_BY_DEFAULT
	| KW_CATEGORIES_ROOT_BY_DEFAULT
	| KW_CATEGORIES_NONROOT_BY_DEFAULT
	| KW_AMBIGUITY_DISALLOWED
	| KW_AMBIGUITY_RESOLVED_BY_PRECEDENCE
	;

production machineDefinitionBody =
	statement*
	;

production statement =
	categoryStatement
	| productionStatement
	| patternStatement
	| regexStatement
	;

pattern attributableStatementElaboration =
	(OP_COLON declarationNameList)? CURLY_LEFT memberDeclaration* CURLY_RIGHT
	;

pattern typeFormingStatementElaboration =
	(KW_ROOT|KW_IGNORED KW_ROOT)?
	;

production categoryStatement =
	typeFormingStatementElaboration KW_CATEGORY IDENTIFIER attributableStatementElaboration OP_SEMICOLON
	;

production memberDeclaration =
	KW_FLAG IDENTIFIER OP_SEMICOLON
	| KW_RAW IDENTIFIER OP_SEMICOLON
	| IDENTIFIER (KW_LIST|KW_ITEM)? IDENTIFIER OP_SEMICOLON
	;

pattern categoryStatementBody =
	IDENTIFIER*
	;

production productionStatement =
	typeFormingStatementElaboration
    terminalityElaboration
    KW_PRODUCTION? IDENTIFIER attributableStatementElaboration OP_EQUALS
        ruleStatementBody
    OP_SEMICOLON
	;

pattern terminalityElaboration =
	(KW_TERMINAL | KW_NONTERMINAL)?
	;

production patternStatement =
	KW_PATTERN IDENTIFIER attributableStatementElaboration OP_EQUALS
        ruleStatementBody
    OP_SEMICOLON
	;

production regexStatement =
	KW_REGEX IDENTIFIER OP_EQUALS
		ruleStatementBody
	OP_SEMICOLON
	;

production ruleStatementBody = 
	disjunctiveRegex?
	;

production disjunctiveRegex =
	conjuctiveRegex (OP_OR conjuctiveRegex)*
	;

production conjunctiveRegex =
	rootRegex+
	;

production rootRegex =
	(repetitiveRegex | atomicRegex) actionTag*
	;

production actionTag = 
	OP_AT action OP_COLON IDENTIFIER
	;

pattern action =
	| KW_FLAG
	| KW_UNFLAG
	| KW_CAPTURE
	| KW_EMPTY
	| KW_APPEND
	| KW_PREPEND
	| KW_SET
	| KW_UNSET
	| KW_PUSH
	| KW_POP
	| KW_CLEAR
	;

production repetitiveRegex =
	atomicRegex OP_QM
	| atomicRegex OP_STAR
	| atomicRegex OP_PLUS
	| atomicRegex CURLY_LEFT NUMBER, NUMBER CURLY_RIGHT
	;
	
production atomicRegex =
	PAR_LEFT disjunctiveRegex PAR_RIGHT
	| SQUARE_LEFT OP_CARET (STRING|regexRange)+ SQUARE_RIGHT
	| SQUARE_LEFT (STRING|regexRange)+ SQUARE_RIGHT
	| STRING
	| (KW_EMPTY | PAR_LEFT PAR_RIGHT)
	| OP_DOT
	| referenceRegex
	;

production regexRange =
	STRING OP_DASH STRING
	;

production referenceRegex =
	IDENTIFIER
	;
```